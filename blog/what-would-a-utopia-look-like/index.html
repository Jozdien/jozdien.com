<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> What Would a Utopia Look Like? </title>
  <link rel="stylesheet" href="styles.css">
</head>

<body>
	<div class="home">
		<div class="link">
			<a href="../../index.html">
				Jozdien
			</a>
		</div>
	</div>
	<div class="main">
		<div class="head">
			<div class="title">
				What Would a Utopia Look Like?
			</div>
			<div class="details">
				<div class="type">
					Blog
				</div>
				<div class="date">
					1 Jan 2021
				</div>
				<div class="count">
					Words: 1609
				</div>
			</div>
		</div>
		<div class="content">
			Utopias are hard to believe in.  
			<br><br>
			Our basis for normality - and thus for our frame of reference for the world - obviously follows from what we’ve seen and experienced in the world around us.  But utopias are hard to write, so, never seeing them, we’re left with a glaring emptiness in place of cached thoughts on the future actually hitting ceilings of hedonism.  
			<br><br>
			When you’re a writer trying to create a utopian world, historically, you’ll end up at one of a few kinds of stories.  You either envision a world that seems perfect to its people - as in <i>Brave New World</i>, for the most part - but that we can see is flawed from our morality; thus hardly qualifying as a utopia to us.  Or you create a seemingly utopian world, filled with a hedonic people, but which harbours one sinister secret that breaks the illusion - in some stories, these arise as a natural consequence of trying to build a utopia.  If you really tried to think of a perfect world, you’d probably realize you were wasting your time; utopias are boring.  <a href="https://www.lesswrong.com/posts/xdQLAncGvXHuaGtbY/the-challenge-of-writing-utopia" target="_blank">Writing needs challenges for the characters. </a>
			<br><br>
			This criticism follows through to the real world.  <a href="https://www.lesswrong.com/posts/K4aGvLnHvYgX9pZHS/the-fun-theory-sequence" target="_blank">The idea of eternal boredom is commonly touted as an argument against life extension, transhumanism, and sometimes the ideal of a better future.</a>  At first glance, it may seem like undeniable rhetoric - people routinely get bored with things even today, where opportunities for happiness are far lower than their upper limits (though still higher than all of history).
			<br><br>
			But the future would not resemble the present.  The scientific prowess we would have to develop before we can viably imagine actually creating a utopia is still leagues beyond us (from a technical perspective - from a chronological perspective, it might only be a few decades before we have AGI).  Humans are marvelously bad at predicting the growth of new technologies, but there are few we can speculate of today that we have reason to believe can’t be solved with time and sufficiently large amounts of resources (which we might obtain through interstellar exploration or on a long enough timeline, stuff like Dyson spheres).  Some modern ideas may run against what we consider today to be fundamental laws of physics, but those are irrelevant to the scope of this discussion.
			<br><br>
			The technologies we would conceivably need to build a utopia would center around exerting absolute control over our environment.  Most if not all problems we face in modern society originate from priors in our native environment that we take for granted - the physical weaknesses of our species, resource scarcity, natural disasters, and on a meta level, characteristics of humanity such as greed or hatred that resulted from evolution.  The former seems more obviously workable - genetic modification or transitioning to digital minds, interstellar capital, all weaken the direct hold of the natural world on us.  But its indirect hold, the <i>results</i> of natural processes that form a part of us, appears to be harder problems even to properly define.
			<br><br>
			But humans aren’t special, not from a physical sense.  Even the human mind can be described in terms of signals, subroutines, and memory storage, even if trying to do so would far exceed our current technical capacity.  So it is <i>possible</i>, given enough technological superiority like a sufficiently advanced AGI would possess, to alter the presuppositions of the human mind.  In other words, we might have the power to eliminate the negative results of evolution - hate, anger, a plethora of psychological effects we try to overcome in our daily lives anyway, and yes, boredom.  
			<br><br>
			Boredom was, and is, useful in our native environment for the purpose of scientific advancement.  But in a future world where advancing technology’s returns on the human condition stop compensating for a state less than perfect hedonism, we can imagine editing boredom out of our lives, or allowing one direct control over when and how they experience it. 
			<br><br>
			This seems like an alarming proposition.  We’re talking about changing what we fundamentally <i>are</i>, after all.  But consider that we already do that in our daily lives.  One might try to distance themselves from certain people because they feel terrible in their company, or from certain communities, even well-aligned ones, because constant feelings of hatred and anger are unhealthy.  The most common argument I foresee against this is that giving us root control over our own emotions removes unpredictability, and thus a vital component of what excites us.  Whether that’s true is a discussion beyond the scope of this, but I will say that if it is true, the obvious follow-up is that we can change <i>that</i> as well, and make our subjective experience post-transition as enjoyable as before.  There are various philosophical arguments against this as well, but I think they lack merit in this scenario.
			<br><br>
			Getting back on track, what would a utopia then look like?  We’ve assumed something approximating perfect control over our environment.  By that point we’d most likely have moved beyond physical bodies and any sort of self analogous to something easily inferred by our present selves, but for the sake of clarity, I will use as an assumption that we’re still born into human bodies, and live in a society that, while not similar to ours in content, is in structure.  
			<br><br>
			From the very beginning of life, we’d want to remove all potential for defects in the bodies inhabited by future humans.  In fact, while we’re at it, why not give everyone a perfect body?  And since by that point we’d have the intelligence to actually distinguish extremely minor variations in the genetic code that would give one individual an advantage over another, it seems <i>humane</i>, and <i>moral</i> to work off of an ideal genetic template for all individuals (this already carries certain dystopian overtones mimicking <i>Brave New World</i>, but consider what themes in that book carried the negative - not every new idea expressed in a dystopian novel is necessary to a dystopia, some are just used to fit negative ideals).
			<br><br>
			What happens after birth?  Even today, we’ve eliminated a great number of hindrances to proper human growth from many countries, such as malnutrition.  It thus makes sense to remove all possible hindrances we can from a child’s life, such as the potential for disease or wounds (remember: by this point, we’d be past the stage where life is inherently unfair and a source of occasional pain that children today have to learn to tolerate to survive), or even anything less than the absolute best care that can be provided to instill the values we cherish.  Because children end up with different levels of advantage from different levels of care (children of rich people often ending up better suited to accomplishing their goals than children of poorer people even if their financial status is removed after the fact), it again seems morally right to give everyone the exact same level of maximal care.  Remember, this would be an environment filled with substantially more joy and delight than even our best nurseries today, while still nurturing in them the ideals we value.
			<br><br>
			What would the real world look like, after adolescence?  Everything in our space would be of our design, leaving anything up to the temptations of chance would seem unfair to the people who would be affected by it.  So from birth to life, their life is a perfectly arranged paradise.  And unlike in stories, this wouldn’t be seceded by some hidden negative effect we no longer have the capacity to handle because we’ve grown up in bliss, any more than our modern society runs the risk of all writing surfaces in the world disappearing and having to accustom ourselves to communicating without it, like people did hundreds of years ago.
			<br><br>
			At this point, you might realize that every person created out of this system, while what we would call today ideal individuals, are all identical.  Personalities, ideas, interests, skills, are formed of genetics and nurture, both of which we’ve now optimized to the ideals.  What we’re left with is a society filled with identical individuals, in body and mind (by that point, us, the inhabitants of Old Earth, would most likely have altered ourselves of our own volition to perfection - and over time and the social nature of humanity, that idea of perfection would probably converge; if it appears like it might not, that’s where this analogy of still-physical bodies resembling humans today fails - what we’d have then would be so far removed from what we know today that we wouldn’t have strong preconceptions of what forms in that nearly infinite possibility space we’d consider ideal).
			<br><br>
			I’ll admit to a good level of personal horror at that thought at first.  <a href="https://www.lesswrong.com/posts/hQSaMafoizBSa3gFR/eutopia-is-scary" target="_blank">But utopias are scary by design.</a>  Even a smart someone from the past would be horrified at our present.  It isn’t <i>just</i> values dissonance - someone intelligent enough would probably agree that life is better - it’s also demonstrative of the extent to which normality rules over our judgement.
			<br><br>
			When you view the future as a perfect paradise filled with trillions - or more - copies of functionally the same sentient being, it doesn’t seem like a utopia.  Not even like a flawed utopia.  Our first reaction probably screams dystopia.  But to not control nature when we have the power to, can be seen as a great act of evil, considering the relative pain or lack of happiness we’re inflicting on people from that choice.  Perhaps if we break down the transition from our modern society to that world, into steps more normal to us, you might find that at every point, the choices leading to that utopia is consistent with your stated moral values.
		</div>
	</div>
</body>